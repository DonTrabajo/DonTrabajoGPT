# === Offline LLM defaults (Ollama) ===
LOCAL_LLM=true
OPENAI_BASE_URL=http://127.0.0.1:11434/v1
OPENAI_API_KEY=ollama
LLM_MODEL=llama3.1-local

# Optional local RAG sidecar (if you run it)
RAG_URL=

# Persona/system prompt (from PR #1)
DONTRABAJO_SYSTEM=tools/oss_persona/persona_prompt.txt

# Where to read findings (for summaries)
ARTIFACTS_DIR=artifacts
ARTIFACT_PATTERNS=linpeas*.json,findings*.json,*.txt

# Where to save AI summaries
NOTES_DIR=notes
