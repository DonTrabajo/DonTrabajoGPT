import os, re, json
from typing import List, Dict
from rich.console import Console
from dotenv import load_dotenv

from .model import OllamaChat
from .prompts import SYSTEM_PROMPT
from .schema import ToolCall
from .tools import registry as tool_registry
from .persona_loader import load_persona_text

console = Console()
TOOL_RE = re.compile(r"```tool\s*(\{.*?\})\s*```", re.DOTALL)

class Agent:
    def __init__(self, model: OllamaChat, tools: dict, show_cot: bool, max_turns: int = 8, system_prompt: str | None = None):
        self.model = model
        self.tools = tools
        self.show_cot = show_cot
        self.max_turns = max_turns
        self.system_prompt = system_prompt or SYSTEM_PROMPT

    @classmethod
    def from_env(cls):
        load_dotenv(dotenv_path="tools/agent/.env", override=False)
        model_name = os.getenv("MODEL_NAME", "gpt-oss-20b")
        base = os.getenv("OLLAMA_BASE", "http://localhost:11434")
        temp = float(os.getenv("TEMPERATURE", "0.2"))
        num_ctx = int(os.getenv("NUM_CTX", "16384"))
        max_turns = int(os.getenv("MAX_TURNS", "8"))
        show_cot = os.getenv("SHOW_CHAIN_OF_THOUGHT", "false").lower() == "true"
        enable_shell = os.getenv("ENABLE_SHELL", "false").lower() == "true"
        enable_py = os.getenv("ENABLE_PYTHON", "true").lower() == "true"
        enable_fs = os.getenv("ENABLE_FS", "true").lower() == "true"
        persona_file = os.getenv("PERSONA_FILE", "")
        persona_text = load_persona_text(persona_file)

        tools = tool_registry(enable_shell=enable_shell, enable_python=enable_py, enable_fs=enable_fs)
        model = OllamaChat(model=model_name, base_url=base, temperature=temp, num_ctx=num_ctx)

        system_prompt = SYSTEM_PROMPT
        if persona_text:
            system_prompt = persona_text + "\n\n" + SYSTEM_PROMPT

        return cls(model, tools, show_cot, max_turns, system_prompt=system_prompt)

    def run(self, user_prompt: str) -> str:
        last_reply = ""
        messages: List[Dict[str, str]] = [
            {"role": "system", "content": self.system_prompt},
            {"role": "user", "content": "You can browse, call tools, run small code snippets, and then provide a final answer. If a task requires current info, prefer web.search + web.get."},
            {"role": "user", "content": user_prompt},
        ]

        did_tool = False
        for _ in range(self.max_turns):
            reply = self.model.chat(messages).strip()
            last_reply = reply or last_reply

            # Optional: debug scratchpad
            if self.show_cot:
                if "FINAL_ANSWER:" in reply:
                    reasoning = reply.split("FINAL_ANSWER:", 1)[0].strip()
                    if reasoning:
                        console.rule("[bold magenta]Reasoning[/bold magenta]")
                        console.print(reasoning)
                else:
                    console.rule("[bold magenta]Reasoning[/bold magenta]")
                    console.print(reply)

            # Tool call?
            m = TOOL_RE.search(reply)
            if m:
            else:
                # BOOTSTRAP WEB.SEARCH: help the model start a search if it didn't call a tool yet
                if not did_tool and _ < 2 and "web.search" in (user_prompt + reply).lower():
                    try:
                        import json as _json, re as _re
                        m_q = _re.search(r'"([^"]+)"', user_prompt)
                        query = m_q.group(1) if m_q else user_prompt
                        out = self.tools["web.search"](query=query, max_results=3)
                        obs = {"tool": "web.search", "output": out}
                        messages.append({"role": "tool", "name": "web.search", "content": _json.dumps(obs)})
                        did_tool = True
                        continue
                    except Exception:
                        pass
                # Gentle reminder
                messages.append({"role":"system","content":"Remember: either emit a ```tool {...}``` block OR finish with a single line starting with FINAL_ANSWER: <text>. No other prose."})

                tool_json = m.group(1)
                try:
                    call = ToolCall.model_validate_json(tool_json)
                except Exception as e:
                    messages.append({"role": "tool", "name": "parser", "content": json.dumps({"error": f"Invalid tool JSON: {e}"})})
                    continue

                obs = self._dispatch(call)
                messages.append({"role": "tool", "name": call.tool, "content": json.dumps(obs)})
                continue

            # Final answer?
            if "FINAL_ANSWER:" in reply:
                return reply.split("FINAL_ANSWER:", 1)[1].strip()

            # Keep looping
            messages.append({"role": "assistant", "content": reply})

        return last_reply if last_reply else "[Agent] Max turns reached without a final answer."

    def _dispatch(self, call: ToolCall):
        fn = self.tools.get(call.tool)
        if not fn:
            return {"tool": call.tool, "error": "Unknown tool"}
        try:
            out = fn(**call.input)
            return {"tool": call.tool, "output": out}
        except TypeError as e:
            return {"tool": call.tool, "error": f"Bad args: {e}"}
        except Exception as e:
            return {"tool": call.tool, "error": str(e)}
