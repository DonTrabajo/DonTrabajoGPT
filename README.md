# Don Trabajo GPT ğŸ¤–ğŸ’€

> A GPT-powered, terminal-native hacking assistant for offensive security labs, red teams, and cyberpunk operators â€” now with **Offline-First** superpowers.

[![MIT License](https://img.shields.io/github/license/DonTrabajo/DonTrabajoGPT)](LICENSE)  
[![Last Commit](https://img.shields.io/github/last-commit/DonTrabajo/DonTrabajoGPT)](https://github.com/DonTrabajo/DonTrabajoGPT/commits/main)  
[![Languages](https://img.shields.io/github/languages/top/DonTrabajo/DonTrabajoGPT)](https://github.com/DonTrabajo/DonTrabajoGPT)  
[![Stars](https://img.shields.io/github/stars/DonTrabajo/DonTrabajoGPT?style=social)](https://github.com/DonTrabajo/DonTrabajoGPT/stargazers)

---

## ğŸ¯ Purpose

**Don Trabajo GPT** is a lightweight, terminal-native AI assistant that augments red-team ops and offensive-security workflows. It parses **linPEAS**, matches **CVEs**, validates toolchains, andâ€”when you need itâ€”spins up a **fully local LLM** to summarize findings and draft next steps with **zero** cloud calls. Your data stays where it belongs: on your machine.

---

## âœ¨ Core Features

- **linPEAS pipeline**: preprocess â†’ parse â†’ triage  
- **CVE matcher**: extract and rank potential issues from JSON  
- **Tool path validation**: sanity-check required binaries  
- **Local LLM (Offline-First)**: summarize findings & generate next steps via **Ollama** (OpenAI-compatible, 100% local)  
- **Clean TUI**: Rich-powered CLI with color, panels, and smooth UX  
- **Demo-ready**: Copy/paste quick starts + smoke tests for talks

---

## ğŸ“¸ Screenshots & Terminal Preview

```
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Don Trabajo GPT            â”‚
â”‚ CyberOps Console Interface â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
???????????????????????????????????????????????????????????
? Option   ? Feature                        ? Status       ?
???????????????????????????????????????????????????????????
Ñ– 0        Ñ– Preprocess linPEAS Raw Output  Ñ– ğŸ†•            Ñ–
Ñ– 1        Ñ– Parse linPEAS Output           Ñ– âœ… Ready      Ñ–
Ñ– 2        Ñ– Run CVE Matcher                Ñ– âœ… Ready      Ñ–
Ñ– 3        Ñ– Tool Path Validation           Ñ– âœ… Ready      Ñ–
Ñ– 4        Ñ– HTB Log Tracker                Ñ– Coming Soon  Ñ–
Ñ– 5        Ñ– Launch Discord Bot             Ñ– Coming Soon  Ñ–
Ñ– 6        Ñ– Offline LLM (Local Persona)    Ñ– Beta         Ñ–
Ñ– 7        Ñ– Full linPEAS Analyzer (combo)  Ñ– Beta         Ñ–
Ñ– 8        Ñ– Exit                           Ñ–              Ñ–
ĞĞ”Ğ”Ğ”Ğ”Ğ”Ğ”Ğ”Ğ”Ğ”Ğ”Ğ‘Ğ”Ğ”Ğ”Ğ”Ğ”Ğ”Ğ”Ğ”Ğ”Ğ”Ğ”Ğ”Ğ”Ğ”Ğ”Ğ”Ğ”Ğ”Ğ”Ğ”Ğ”Ğ”Ğ”Ğ”Ğ”Ğ”Ğ”Ğ”Ğ”Ğ”Ğ”Ğ”Ğ‘Ğ”Ğ”Ğ”Ğ”Ğ”Ğ”Ğ”Ğ”Ğ”Ğ”Ğ”Ğ”Ğ”Ğ”Ğ©
Choose an option [0/1/2/3/4/5/6/7/8]:
```

---

## ğŸš€ Quick Start

```bash
# Clone the repo and enter the folder
git clone https://github.com/DonTrabajo/DonTrabajoGPT.git
cd DonTrabajoGPT

# Create & activate virtual environment
python3 -m venv .venv
source .venv/bin/activate

# Install dependencies
pip install -r requirements.txt

# Validate your tool paths
python validate_tool_paths.py

# Launch the assistant (TUI)
python don_trabajo_gpt.py
```

---

## ğŸ”’ Offline-First Mode (Local LLM)

Run DonTrabajoGPT with a **fully local brain** using [Ollama](https://ollama.ai). No Internet calls; everything stays on your box.

```bash
# 1) Install & start Ollama (macOS)
brew install --cask ollama
ollama serve    # ensures 127.0.0.1:11434 is listening

# 2) Pick a local model you already have (examples)
ollama list
#   deepseek-r1:8b         # lighter/faster
#   gpt-oss:20b            # bigger brain, needs RAM

# 3) Configure DonTrabajoGPT
cp .env.example .env
# In .env set at minimum:
#   OPENAI_BASE_URL=http://127.0.0.1:11434/v1
#   OPENAI_API_KEY=ollama
#   LLM_MODEL=deepseek-r1:8b   # or gpt-oss:20b
```

**Summarize findings (offline):**
```bash
mkdir -p artifacts notes
cp sample_linpeas_output.json artifacts/        # demo artifact
python -m tools.oss_persona.tui_offline_llm     # writes notes/ai_summary_YYYYMMDD-HHMMSS.md
```

**Smoke test (OpenAI-compatible client â†’ Ollama):**
```bash
python - <<'PY'
from openai import OpenAI
c = OpenAI(base_url="http://127.0.0.1:11434/v1", api_key="ollama")
print([m.id for m in c.models.list().data])
PY
```

> **What stays local:** the LLM, prompts, artifacts, mirrors, and notes.  
> **What leaves the laptop:** nothingâ€”unless you explicitly connect to a client network for testing.

---

## ğŸ›ï¸ 5-Minute Demo Recipe (Conference-friendly)

1. Prove no cloud calls:  
   `curl -s http://127.0.0.1:11434/v1/models` âœ…  
2. Put a sample artifact in `artifacts/` (or paste on prompt).  
3. **TUI â†’ Option 6**: Local LLM (offline) summary â†’ generate checklist & next steps.  
4. Show the saved Markdown in `notes/`.  
5. (Optional) Toggle Wi-Fi off and repeat. Still works.

---

## ğŸ“‹ Usage Examples

### Run the TUI
```bash
python don_trabajo_gpt.py
```
Choose options by number:  
- **0** - Preprocess linPEAS raw output  
- **1** - Parse linPEAS JSON output  
- **2** - Match CVEs from linPEAS results  
- **3** - Validate `tool_paths.json`  
- **4** - HTB Log Tracker *(coming soon)*  
- **5** - Discord bot *(coming soon)*  
- **6** - **Local LLM (Offline)**: summarize findings & draft next steps  
- **7** - Full linPEAS analyzer (preprocess â†’ parse â†’ CVE â†’ GPT)  
- **8** - Exit  

### Validate Tool Paths
```bash
python validate_tool_paths.py
# âœ… nmap: /usr/bin/nmap
# âŒ enum4linux: /usr/local/bin/enum4linux
```

### CVE Matcher
```bash
python don_trabajo_gpt.py
# Choose 2 â†’ point to your linPEAS JSON â†’ get ranked findings.
```

### Local LLM (standalone)
```bash
# Uses .env to hit your local Ollama model
python -m tools.oss_persona.tui_offline_llm
```

---

## ğŸ—‚ï¸ Directory Layout

```
DonTrabajoGPT/
|- animated_transition.py
|- cve_matcher.py
|- docs/
|  |- CNAME
|  |- index.html
|- don_trabajo_gpt.py              # Main TUI launcher
|- don_trabajo_gpt_tui.py          # Rich-powered menu UI
|- requirements.txt
|- sample_linpeas_output.json
|- swoosh_transition.py
|- tools/
|  |- oss_persona/
|     |- persona_prompt.txt        # system prompt for local persona
|     |- oss_client.py             # OpenAI-compatible (Ollama) client
|     |- tui_offline_llm.py        # Offline summary runner
|- validate_tool_paths.py
|- .env.example                    # Offline-first config template
|- artifacts/                      # (gitignored) analysis inputs
|- notes/                          # (gitignored) generated summaries
|- LICENSE
|- README.md
```

---

## ğŸ§  Roadmap

| Status     | Feature                                                   |
|------------|-----------------------------------------------------------|
| âœ… Ready   | linPEAS preprocess/parse                                  |
| âœ… Ready   | CVE matcher (JSON)                                        |
| âœ… Ready   | Tool path validation                                      |
| âœ… Ready   | **Local LLM (Offline-First)** via Ollama                  |
| ğŸ”„ WIP     | HTB Log Tracker                                           |
| ğŸ”„ WIP     | Discord Bot (ops logging & notifications)                 |
| â³ Planned | Enum4linux / WinPEAS analyzers                            |
| â³ Planned | Report export (Markdown/HTML one-pager)                   |
| â³ Planned | Plugin system for analyzers (drop-in modules)             |
| â³ Planned | Docs site revamp (screenshots, offline demo walkthrough)  |

---

## âš™ï¸ Configuration (.env)

Copy and tweak:

```env
# === Offline LLM defaults (Ollama) ===
LOCAL_LLM=true
OPENAI_BASE_URL=http://127.0.0.1:11434/v1
OPENAI_API_KEY=ollama
LLM_MODEL=deepseek-r1:8b        # or gpt-oss:20b

# Optional local RAG sidecar (leave empty if not using)
RAG_URL=

# Persona/system prompt
DONTRABAJO_SYSTEM=tools/oss_persona/persona_prompt.txt

# Where to read findings (for summaries)
ARTIFACTS_DIR=artifacts
ARTIFACT_PATTERNS=linpeas*.json,findings*.json,*.txt

# Where to save AI summaries
NOTES_DIR=notes
```

---

## ğŸ§ª Dev Tips

- Use a Python venv (`.venv`) and keep `artifacts/` & `notes/` out of git (already ignored).  
- For talks, prep a `notes/` wipe and an `artifacts/` seed file to reset in seconds.  
- Want a `Makefile`?  
  - `make offline-demo` â†’ env + sample artifact + run Option 6  
  - `make clean-notes` â†’ empty `notes/`

---

## ğŸ‘¤ About the Author

**Don Trabajo** â€” cybersecurity operator, hacker-artist, and creative force behind **Prox Offensive**. Fusing tech with spirit, code with culture, **Don Trabajo GPT** is where tools meet intuition.

> *â€œEnumeration is half the battle. The other half is naming your tools something dope.â€*  
> â€” Don Trabajo

---

## ğŸ“œ License

This project is licensed under the **MIT License**. See [LICENSE](./LICENSE) for details.

---


**Â¡Adelante siempre!**  
*Less heroics. More reliability. Keep the receipts.*








