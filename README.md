# Don Trabajo GPT ğŸ¤–ğŸ’€

> A GPT-powered, terminal-native hacking assistant for offensive security labs, red teams, and cyberpunk operators â€” now with **Offline-First** superpowers.

[![MIT License](https://img.shields.io/github/license/DonTrabajo/DonTrabajoGPT)](LICENSE)  
[![Last Commit](https://img.shields.io/github/last-commit/DonTrabajo/DonTrabajoGPT)](https://github.com/DonTrabajo/DonTrabajoGPT/commits/main)  
[![Languages](https://img.shields.io/github/languages/top/DonTrabajo/DonTrabajoGPT)](https://github.com/DonTrabajo/DonTrabajoGPT)  
[![Stars](https://img.shields.io/github/stars/DonTrabajo/DonTrabajoGPT?style=social)](https://github.com/DonTrabajo/DonTrabajoGPT/stargazers)

---

## ğŸ¯ Purpose

**Don Trabajo GPT** is a lightweight, terminal-native AI assistant that augments red-team ops and offensive-security workflows. It parses **linPEAS**, matches **CVEs**, validates toolchains, andâ€”when you need itâ€”spins up a **fully local LLM** to summarize findings and draft next steps with **zero** cloud calls. Your data stays where it belongs: on your machine.

---

## âœ¨ Core Features

- **linPEAS pipeline**: preprocess â†’ parse â†’ triage  
- **CVE matcher**: extract and rank potential issues from JSON  
- **Tool path validation**: sanity-check required binaries  
- **Local LLM (Offline-First)**: summarize findings & generate next steps via **Ollama** (OpenAI-compatible, 100% local)  
- **Clean TUI**: Rich-powered CLI with color, panels, and smooth UX  
- **Demo-ready**: Copy/paste quick starts + smoke tests for talks

---

## ğŸ“¸ Screenshots & Terminal Preview

```
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Don Trabajo GPT            â”‚
â”‚ CyberOps Console Interface â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Option   â”ƒ Feature                       â”ƒ Status      â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ 0        â”‚ Preprocess linPEAS Raw Output â”‚ ğŸ”¥ New      â”‚
â”‚ 1        â”‚ Parse linPEAS Output          â”‚ âœ… Ready    â”‚
â”‚ 2        â”‚ Run CVE Matcher               â”‚ âœ… Ready    â”‚
â”‚ 3        â”‚ Tool Path Validation          â”‚ âœ… Ready    â”‚
â”‚ 4        â”‚ HTB Log Tracker               â”‚ Coming Soon â”‚
â”‚ 5        â”‚ Launch Discord Bot            â”‚ Coming Soon â”‚
â”‚ 6        â”‚ Exit                          â”‚             â”‚
â”‚ 7        â”‚ Local LLM (Offline) Summary   â”‚ âœ… Ready    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Choose an option [0/1/2/3/4/5/6/7]:
```

---

## ğŸš€ Quick Start

```bash
# Clone the repo and enter the folder
git clone https://github.com/DonTrabajo/DonTrabajoGPT.git
cd DonTrabajoGPT

# Create & activate virtual environment
python3 -m venv .venv
source .venv/bin/activate

# Install dependencies
pip install -r requirements.txt

# Validate your tool paths
python validate_tool_paths.py

# Launch the assistant (TUI)
python don_trabajo_gpt.py
```

---

## ğŸ”’ Offline-First Mode (Local LLM)

Run DonTrabajoGPT with a **fully local brain** using [Ollama](https://ollama.ai). No Internet calls; everything stays on your box.

```bash
# 1) Install & start Ollama (macOS)
brew install --cask ollama
ollama serve    # ensures 127.0.0.1:11434 is listening

# 2) Pick a local model you already have (examples)
ollama list
#   deepseek-r1:8b         # lighter/faster
#   gpt-oss:20b            # bigger brain, needs RAM

# 3) Configure DonTrabajoGPT
cp .env.example .env
# In .env set at minimum:
#   OPENAI_BASE_URL=http://127.0.0.1:11434/v1
#   OPENAI_API_KEY=ollama
#   LLM_MODEL=deepseek-r1:8b   # or gpt-oss:20b
```

**Summarize findings (offline):**
```bash
mkdir -p artifacts notes
cp sample_linpeas_output.json artifacts/        # demo artifact
python -m tools.oss_persona.tui_offline_llm     # writes notes/ai_summary_YYYYMMDD-HHMMSS.md
```

**Smoke test (OpenAI-compatible client â†’ Ollama):**
```bash
python - <<'PY'
from openai import OpenAI
c = OpenAI(base_url="http://127.0.0.1:11434/v1", api_key="ollama")
print([m.id for m in c.models.list().data])
PY
```

> **What stays local:** the LLM, prompts, artifacts, mirrors, and notes.  
> **What leaves the laptop:** nothingâ€”unless you explicitly connect to a client network for testing.

---

## ğŸ›ï¸ 5-Minute Demo Recipe (Conference-friendly)

1. Prove no cloud calls:  
   `curl -s http://127.0.0.1:11434/v1/models` âœ…  
2. Put a sample artifact in `artifacts/` (or paste on prompt).  
3. **TUI â†’ Option 7**: Local LLM (offline) summary â†’ generate checklist & next steps.  
4. Show the saved Markdown in `notes/`.  
5. (Optional) Toggle Wi-Fi off and repeat. Still works.

---

## ğŸ“‹ Usage Examples

### Run the TUI
```bash
python don_trabajo_gpt.py
```
Choose options by number:  
- **0** â€“ Preprocess linPEAS raw output  
- **1** â€“ Parse linPEAS JSON output  
- **2** â€“ Match CVEs from linPEAS results  
- **3** â€“ Validate `tool_paths.json`  
- **4** â€“ HTB Log Tracker *(coming soon)*  
- **5** â€“ Discord bot *(coming soon)*  
- **6** â€“ Exit  
- **7** â€“ **Local LLM (Offline)**: summarize findings & draft next steps

### Validate Tool Paths
```bash
python validate_tool_paths.py
# âœ… nmap: /usr/bin/nmap
# âŒ enum4linux: /usr/local/bin/enum4linux
```

### CVE Matcher
```bash
python don_trabajo_gpt.py
# Choose 2 â†’ point to your linPEAS JSON â†’ get ranked findings.
```

### Local LLM (standalone)
```bash
# Uses .env to hit your local Ollama model
python -m tools.oss_persona.tui_offline_llm
```

---

## ğŸ—‚ï¸ Directory Layout

```
DonTrabajoGPT/
â”œâ”€â”€ animated_transition.py
â”œâ”€â”€ cve_matcher.py
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ CNAME
â”‚   â””â”€â”€ index.html
â”œâ”€â”€ don_trabajo_gpt.py              # Main TUI launcher
â”œâ”€â”€ don_trabajo_gpt_tui.py          # Rich-powered menu UI
â”œâ”€â”€ don_trabajo_discord_bot.py      # (WIP) Discord logging
â”œâ”€â”€ ping.wav
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ sample_linpeas_output.json
â”œâ”€â”€ swoosh_transition.py
â”œâ”€â”€ tools/
â”‚   â””â”€â”€ oss_persona/
â”‚       â”œâ”€â”€ persona_prompt.txt      # system prompt for local persona
â”‚       â”œâ”€â”€ offline_llm_client.py   # OpenAI-compatible (Ollama) client
â”‚       â””â”€â”€ tui_offline_llm.py      # Option 7 runner (offline summary)
â”œâ”€â”€ validate_tool_paths.py
â”œâ”€â”€ .env.example                    # Offline-first config template
â”œâ”€â”€ artifacts/                      # (gitignored) analysis inputs
â”œâ”€â”€ notes/                          # (gitignored) generated summaries
â”œâ”€â”€ LICENSE
â””â”€â”€ README.md
```

---

## ğŸ§  Roadmap

| Status     | Feature                                                   |
|------------|-----------------------------------------------------------|
| âœ… Ready   | linPEAS preprocess/parse                                  |
| âœ… Ready   | CVE matcher (JSON)                                        |
| âœ… Ready   | Tool path validation                                      |
| âœ… Ready   | **Local LLM (Offline-First)** via Ollama                  |
| ğŸ”„ WIP     | HTB Log Tracker                                           |
| ğŸ”„ WIP     | Discord Bot (ops logging & notifications)                 |
| â³ Planned | Enum4linux / WinPEAS analyzers                            |
| â³ Planned | Report export (Markdown/HTML one-pager)                   |
| â³ Planned | Plugin system for analyzers (drop-in modules)             |
| â³ Planned | Docs site revamp (screenshots, offline demo walkthrough)  |

---

## âš™ï¸ Configuration (.env)

Copy and tweak:

```env
# === Offline LLM defaults (Ollama) ===
LOCAL_LLM=true
OPENAI_BASE_URL=http://127.0.0.1:11434/v1
OPENAI_API_KEY=ollama
LLM_MODEL=deepseek-r1:8b        # or gpt-oss:20b

# Optional local RAG sidecar (leave empty if not using)
RAG_URL=

# Persona/system prompt
DONTRABAJO_SYSTEM=tools/oss_persona/persona_prompt.txt

# Where to read findings (for summaries)
ARTIFACTS_DIR=artifacts
ARTIFACT_PATTERNS=linpeas*.json,findings*.json,*.txt

# Where to save AI summaries
NOTES_DIR=notes
```

---

## ğŸ§ª Dev Tips

- Use a Python venv (`.venv`) and keep `artifacts/` & `notes/` out of git (already ignored).  
- For talks, prep a `notes/` wipe and an `artifacts/` seed file to reset in seconds.  
- Want a `Makefile`?  
  - `make offline-demo` â†’ env + sample artifact + run Option 7  
  - `make clean-notes` â†’ empty `notes/`

---

## ğŸ‘¤ About the Author

**Don Trabajo** â€” cybersecurity operator, hacker-artist, and creative force behind **Prox Offensive**. Fusing tech with spirit, code with culture, **Don Trabajo GPT** is where tools meet intuition.

> *â€œEnumeration is half the battle. The other half is naming your tools something dope.â€*  
> â€” Don Trabajo

---

## ğŸ“œ License

This project is licensed under the **MIT License**. See [LICENSE](./LICENSE) for details.

---

**Â¡Adelante siempre!**  
*Less heroics. More reliability. Keep the receipts.*
